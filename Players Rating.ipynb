{"cells":[{"cell_type":"markdown","id":"b83500bd","metadata":{"id":"b83500bd"},"source":["# Supervised Machine Learning Project with PySpark\n","## - Black Belts Team\n","\n","We will be using Player Attribute Table from the European Player Database for this Project. This dataset has 183,978 rows and 43 columns.\n","\n","Learning Outcomes:\n","1. Obtain data using PySpark\n","2. Clean data using PySpark\n","3. Data Exploration using PySpark\n","4. Model Building with PySpark\n","5. Model Evaluation with PySpark"]},{"cell_type":"code","execution_count":null,"id":"d9bf04be","metadata":{"id":"d9bf04be"},"outputs":[],"source":["import warnings\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","import pandas as pd\n","\n","import pyspark\n","from pyspark.sql import functions as F\n","from pyspark.sql import types\n","\n","from pyspark.ml.feature import Imputer, VectorAssembler, StringIndexer\n","from pyspark.ml.regression import RandomForestRegressor, DecisionTreeRegressor, GBTRegressor, LinearRegression\n","from pyspark.ml.evaluation import RegressionEvaluator\n","from pyspark.ml.tuning import CrossValidator, ParamGridBuilder\n","\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","id":"a98c10f1","metadata":{"id":"a98c10f1"},"source":["## Connect to the Spark server\n","\n","We will be using the SparkSession (`spark`) to access our spark cluster.."]},{"cell_type":"code","execution_count":null,"id":"463101a9","metadata":{"id":"463101a9"},"outputs":[],"source":["spark = pyspark.sql.SparkSession.builder.getOrCreate()"]},{"cell_type":"markdown","id":"1c79a595","metadata":{"id":"1c79a595"},"source":["## Obtain the Data\n","\n","We connect to the database and get all available tables"]},{"cell_type":"code","execution_count":null,"id":"b68c141b","metadata":{"scrolled":true,"id":"b68c141b","outputId":"df230af5-e835-41d9-c0c4-31cfaf4c6316"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>type</th>\n","      <th>name</th>\n","      <th>tbl_name</th>\n","      <th>rootpage</th>\n","      <th>sql</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>table</td>\n","      <td>sqlite_sequence</td>\n","      <td>sqlite_sequence</td>\n","      <td>4</td>\n","      <td>CREATE TABLE sqlite_sequence(name,seq)</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>table</td>\n","      <td>Player_Attributes</td>\n","      <td>Player_Attributes</td>\n","      <td>11</td>\n","      <td>CREATE TABLE \"Player_Attributes\" (\\n\\t`id`\\tIN...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>table</td>\n","      <td>Player</td>\n","      <td>Player</td>\n","      <td>14</td>\n","      <td>CREATE TABLE `Player` (\\n\\t`id`\\tINTEGER PRIMA...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>table</td>\n","      <td>Match</td>\n","      <td>Match</td>\n","      <td>18</td>\n","      <td>CREATE TABLE `Match` (\\n\\t`id`\\tINTEGER PRIMAR...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>table</td>\n","      <td>League</td>\n","      <td>League</td>\n","      <td>24</td>\n","      <td>CREATE TABLE `League` (\\n\\t`id`\\tINTEGER PRIMA...</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>table</td>\n","      <td>Country</td>\n","      <td>Country</td>\n","      <td>26</td>\n","      <td>CREATE TABLE `Country` (\\n\\t`id`\\tINTEGER PRIM...</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>table</td>\n","      <td>Team</td>\n","      <td>Team</td>\n","      <td>29</td>\n","      <td>CREATE TABLE \"Team\" (\\n\\t`id`\\tINTEGER PRIMARY...</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>table</td>\n","      <td>Team_Attributes</td>\n","      <td>Team_Attributes</td>\n","      <td>2</td>\n","      <td>CREATE TABLE `Team_Attributes` (\\n\\t`id`\\tINTE...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    type               name           tbl_name  rootpage  \\\n","0  table    sqlite_sequence    sqlite_sequence         4   \n","1  table  Player_Attributes  Player_Attributes        11   \n","2  table             Player             Player        14   \n","3  table              Match              Match        18   \n","4  table             League             League        24   \n","5  table            Country            Country        26   \n","6  table               Team               Team        29   \n","7  table    Team_Attributes    Team_Attributes         2   \n","\n","                                                 sql  \n","0             CREATE TABLE sqlite_sequence(name,seq)  \n","1  CREATE TABLE \"Player_Attributes\" (\\n\\t`id`\\tIN...  \n","2  CREATE TABLE `Player` (\\n\\t`id`\\tINTEGER PRIMA...  \n","3  CREATE TABLE `Match` (\\n\\t`id`\\tINTEGER PRIMAR...  \n","4  CREATE TABLE `League` (\\n\\t`id`\\tINTEGER PRIMA...  \n","5  CREATE TABLE `Country` (\\n\\t`id`\\tINTEGER PRIM...  \n","6  CREATE TABLE \"Team\" (\\n\\t`id`\\tINTEGER PRIMARY...  \n","7  CREATE TABLE `Team_Attributes` (\\n\\t`id`\\tINTE...  "]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["import sqlite3\n","import matplotlib.pyplot as plt\n","\n","database = 'database.sqlite'\n","conn = sqlite3.connect(database)\n","\n","tables = pd.read_sql(\"\"\"SELECT *\n","                        FROM sqlite_master\n","                        WHERE type='table';\"\"\", conn)\n","tables"]},{"cell_type":"markdown","id":"5243c675","metadata":{"id":"5243c675"},"source":["We Select the Dataset Table (Player_Attributes) and save it as a CSV file to be used in spark"]},{"cell_type":"code","execution_count":null,"id":"8e9bbe92","metadata":{"id":"8e9bbe92"},"outputs":[],"source":["df = pd.read_sql(\"\"\"SELECT * FROM Player_Attributes;\"\"\", conn)\n","df.to_csv(\"Player_Attributes.csv\")"]},{"cell_type":"markdown","id":"YWvDwIvVwSaW","metadata":{"id":"YWvDwIvVwSaW"},"source":["Read the dataset using spark"]},{"cell_type":"code","execution_count":null,"id":"ef511bfb","metadata":{"scrolled":false,"id":"ef511bfb","outputId":"f6817599-25e5-4934-f79b-b8b248819080"},"outputs":[{"name":"stdout","output_type":"stream","text":["root\n"," |-- _c0: integer (nullable = true)\n"," |-- id: integer (nullable = true)\n"," |-- player_fifa_api_id: integer (nullable = true)\n"," |-- player_api_id: integer (nullable = true)\n"," |-- date: timestamp (nullable = true)\n"," |-- overall_rating: double (nullable = true)\n"," |-- potential: double (nullable = true)\n"," |-- preferred_foot: string (nullable = true)\n"," |-- attacking_work_rate: string (nullable = true)\n"," |-- defensive_work_rate: string (nullable = true)\n"," |-- crossing: double (nullable = true)\n"," |-- finishing: double (nullable = true)\n"," |-- heading_accuracy: double (nullable = true)\n"," |-- short_passing: double (nullable = true)\n"," |-- volleys: double (nullable = true)\n"," |-- dribbling: double (nullable = true)\n"," |-- curve: double (nullable = true)\n"," |-- free_kick_accuracy: double (nullable = true)\n"," |-- long_passing: double (nullable = true)\n"," |-- ball_control: double (nullable = true)\n"," |-- acceleration: double (nullable = true)\n"," |-- sprint_speed: double (nullable = true)\n"," |-- agility: double (nullable = true)\n"," |-- reactions: double (nullable = true)\n"," |-- balance: double (nullable = true)\n"," |-- shot_power: double (nullable = true)\n"," |-- jumping: double (nullable = true)\n"," |-- stamina: double (nullable = true)\n"," |-- strength: double (nullable = true)\n"," |-- long_shots: double (nullable = true)\n"," |-- aggression: double (nullable = true)\n"," |-- interceptions: double (nullable = true)\n"," |-- positioning: double (nullable = true)\n"," |-- vision: double (nullable = true)\n"," |-- penalties: double (nullable = true)\n"," |-- marking: double (nullable = true)\n"," |-- standing_tackle: double (nullable = true)\n"," |-- sliding_tackle: double (nullable = true)\n"," |-- gk_diving: double (nullable = true)\n"," |-- gk_handling: double (nullable = true)\n"," |-- gk_kicking: double (nullable = true)\n"," |-- gk_positioning: double (nullable = true)\n"," |-- gk_reflexes: double (nullable = true)\n","\n"]}],"source":["data = spark.read.csv(\"Player_Attributes.csv\",\n","                     sep=',',\n","                     inferSchema=True,\n","                     header=True,\n","                     multiLine=True)\n","\n","data.printSchema()"]},{"cell_type":"markdown","id":"98fa17d9","metadata":{"id":"98fa17d9"},"source":["Now lets see the shape of the data"]},{"cell_type":"code","execution_count":null,"id":"dccba260","metadata":{"scrolled":false,"id":"dccba260","outputId":"7243c29f-f228-418d-aef8-61abf35eb66b"},"outputs":[{"name":"stdout","output_type":"stream","text":["(183978, 43)\n"]}],"source":["print((data.count(), len(data.columns)))"]},{"cell_type":"markdown","id":"5071df4c","metadata":{"papermill":{"duration":0.01934,"end_time":"2022-08-12T11:27:38.341867","exception":false,"start_time":"2022-08-12T11:27:38.322527","status":"completed"},"tags":[],"id":"5071df4c"},"source":["## Data Cleaning\n"]},{"cell_type":"markdown","id":"bcfee4f4","metadata":{"id":"bcfee4f4"},"source":["Drop useless columns"]},{"cell_type":"code","execution_count":null,"id":"11f00afd","metadata":{"execution":{"iopub.execute_input":"2022-08-12T11:27:38.382652Z","iopub.status.busy":"2022-08-12T11:27:38.382230Z","iopub.status.idle":"2022-08-12T11:27:38.437767Z","shell.execute_reply":"2022-08-12T11:27:38.436657Z"},"papermill":{"duration":0.078842,"end_time":"2022-08-12T11:27:38.440274","exception":false,"start_time":"2022-08-12T11:27:38.361432","status":"completed"},"tags":[],"id":"11f00afd"},"outputs":[],"source":["# these columns are useless to us, drop them\n","drop_cols = ['_c0', 'id','player_fifa_api_id','player_api_id']\n","\n","data = data.drop(*drop_cols)"]},{"cell_type":"markdown","id":"7wYZiYOuwzes","metadata":{"id":"7wYZiYOuwzes"},"source":["Drop Missing Data"]},{"cell_type":"code","execution_count":null,"id":"d5083399","metadata":{"id":"d5083399"},"outputs":[],"source":["data = data.na.drop()"]},{"cell_type":"markdown","id":"AzFLhJfcw8r0","metadata":{"id":"AzFLhJfcw8r0"},"source":["Lets see the effect of the previous steps on the shape of the dataset"]},{"cell_type":"code","execution_count":null,"id":"d042aa40","metadata":{"scrolled":true,"id":"d042aa40","outputId":"8b74de8e-8811-43d5-b3b1-51e6fad2af01"},"outputs":[{"name":"stdout","output_type":"stream","text":["(180354, 39)\n"]}],"source":["print((data.count(), len(data.columns)))"]},{"cell_type":"markdown","id":"55d0868f","metadata":{"id":"55d0868f"},"source":["We don't need the full Timestamp, so we will add to columns for the year and month. Then delete the date column"]},{"cell_type":"code","execution_count":null,"id":"b9ee8b7e","metadata":{"id":"b9ee8b7e"},"outputs":[],"source":["data = data.withColumn('year', F.year(F.col('date')))\n","data = data.withColumn('month', F.month(F.col('date')))\n","\n","data = data.drop('date')"]},{"cell_type":"markdown","id":"e0d7f93e","metadata":{"id":"e0d7f93e","papermill":{"duration":0.030767,"end_time":"2022-08-12T11:27:39.360409","exception":false,"start_time":"2022-08-12T11:27:39.329642","status":"completed"},"tags":[]},"source":["### Descriptive Statistics\n","We are looking for the summary for some of the imoortant numerical columns"]},{"cell_type":"code","execution_count":null,"id":"a1fb50fd","metadata":{"execution":{"iopub.execute_input":"2022-08-12T11:27:39.404919Z","iopub.status.busy":"2022-08-12T11:27:39.404360Z","iopub.status.idle":"2022-08-12T11:27:53.554571Z","shell.execute_reply":"2022-08-12T11:27:53.552844Z"},"papermill":{"duration":14.176189,"end_time":"2022-08-12T11:27:53.558635","exception":false,"start_time":"2022-08-12T11:27:39.382446","status":"completed"},"tags":[],"id":"a1fb50fd","outputId":"0aa6f52b-ce1f-467d-d3e2-cea0aec33f2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+------------------+\n","|summary|   overall_rating|        potential|        finishing|         crossing|           balance|            vision|          strength|              year|\n","+-------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+------------------+\n","|  count|           180354|           180354|           180354|           180354|            180354|            180354|            180354|            180354|\n","|   mean|68.63531720948801|73.47945706776673|49.96213557780809|55.14207059449749| 65.19008172815684| 57.86817592068931| 67.43247723920733|2012.5871175576922|\n","| stddev|7.027950024610432|6.581962574918881|19.04176034040408|17.24723051650521|13.076191953149287|15.152408257341522|12.085131456050377|2.5694132962377934|\n","|    min|             33.0|             39.0|              1.0|              1.0|              12.0|               1.0|              10.0|              2007|\n","|    25%|             64.0|             69.0|             34.0|             45.0|              58.0|              49.0|              60.0|              2011|\n","|    50%|             69.0|             74.0|             53.0|             59.0|              67.0|              60.0|              69.0|              2013|\n","|    75%|             73.0|             78.0|             65.0|             68.0|              74.0|              69.0|              76.0|              2015|\n","|    max|             94.0|             97.0|             97.0|             95.0|              96.0|              97.0|              96.0|              2016|\n","+-------+-----------------+-----------------+-----------------+-----------------+------------------+------------------+------------------+------------------+\n","\n"]}],"source":["data.select('overall_rating', 'potential', 'finishing','crossing','balance','vision','strength','year').summary().show()"]},{"cell_type":"markdown","id":"e2903cb1","metadata":{"id":"e2903cb1"},"source":["## Data Exploration\n"]},{"cell_type":"markdown","id":"00c52bca","metadata":{"id":"00c52bca"},"source":["looking for the preferred_foot column distribution"]},{"cell_type":"code","execution_count":null,"id":"c61299c8","metadata":{"id":"c61299c8","outputId":"bb495f45-833b-4320-d932-f3bbdfa6f3dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["+--------------+------+\n","|preferred_foot| total|\n","+--------------+------+\n","|         right|136247|\n","|          left| 44107|\n","+--------------+------+\n","\n"]}],"source":["data.registerTempTable('data')\n","\n","state_counts = spark.sql(r\"\"\"SELECT preferred_foot, COUNT(preferred_foot) AS total \n","                                     FROM data \n","                                     GROUP BY preferred_foot \n","                                     ORDER BY total desc \"\"\")\n","state_counts.show()"]},{"cell_type":"markdown","id":"15427e0e","metadata":{"id":"15427e0e"},"source":["looking for the attacking_work_rate column distribution"]},{"cell_type":"code","execution_count":null,"id":"bee8d3af","metadata":{"scrolled":true,"id":"bee8d3af","outputId":"d75d09f3-0d6c-4223-9d71-52b7798fd569"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------------+------+\n","|attacking_work_rate| total|\n","+-------------------+------+\n","|             medium|125070|\n","|               high| 42823|\n","|                low|  8569|\n","|               None|  3317|\n","|               norm|   317|\n","|                  y|    94|\n","|               stoc|    86|\n","|                 le|    78|\n","+-------------------+------+\n","\n"]}],"source":["data.registerTempTable('data')\n","\n","state_counts = spark.sql(r\"\"\"SELECT attacking_work_rate, COUNT(attacking_work_rate) AS total \n","                                     FROM data \n","                                     GROUP BY attacking_work_rate \n","                                     ORDER BY total desc \"\"\")\n","state_counts.show()"]},{"cell_type":"markdown","id":"8d7f1b2d","metadata":{"id":"8d7f1b2d"},"source":["looking for the defensive_work_rate column distribution"]},{"cell_type":"code","execution_count":null,"id":"1f5b6091","metadata":{"scrolled":false,"id":"1f5b6091","outputId":"7cfe8702-b8fd-4516-f388-7272125a1d2d"},"outputs":[{"name":"stdout","output_type":"stream","text":["+-------------------+------+\n","|defensive_work_rate| total|\n","+-------------------+------+\n","|             medium|130846|\n","|               high| 27041|\n","|                low| 18432|\n","|                  o|  1328|\n","|                  1|   421|\n","|                  2|   334|\n","|              ormal|   317|\n","|                  3|   243|\n","|                  5|   231|\n","|                  7|   207|\n","|                  0|   188|\n","|                  6|   179|\n","|                  9|   143|\n","|                  4|   116|\n","|                 es|    94|\n","|              tocky|    86|\n","|                ean|    78|\n","|                  8|    70|\n","+-------------------+------+\n","\n"]}],"source":["data.registerTempTable('data')\n","\n","state_counts = spark.sql(r\"\"\"SELECT defensive_work_rate, COUNT(defensive_work_rate) AS total \n","                                     FROM data \n","                                     GROUP BY defensive_work_rate \n","                                     ORDER BY total desc \"\"\")\n","state_counts.show()"]},{"cell_type":"markdown","id":"c02515a6","metadata":{"id":"c02515a6"},"source":["## Data Preparation for ML"]},{"cell_type":"markdown","id":"30a668c2","metadata":{"papermill":{"duration":0.025242,"end_time":"2022-08-12T11:30:56.843113","exception":false,"start_time":"2022-08-12T11:30:56.817871","status":"completed"},"tags":[],"id":"30a668c2"},"source":["### Imputation"]},{"cell_type":"markdown","id":"23ae17d7","metadata":{"papermill":{"duration":0.043741,"end_time":"2022-08-12T11:31:08.310889","exception":false,"start_time":"2022-08-12T11:31:08.267148","status":"completed"},"tags":[],"id":"23ae17d7"},"source":["Then we will encode all the categorical columns using StringIndexer and drop the original columns."]},{"cell_type":"code","execution_count":null,"id":"9df1469f","metadata":{"execution":{"iopub.execute_input":"2022-08-12T11:31:08.383293Z","iopub.status.busy":"2022-08-12T11:31:08.382908Z","iopub.status.idle":"2022-08-12T11:33:12.743874Z","shell.execute_reply":"2022-08-12T11:33:12.742225Z"},"papermill":{"duration":124.391697,"end_time":"2022-08-12T11:33:12.746638","exception":false,"start_time":"2022-08-12T11:31:08.354941","status":"completed"},"tags":[],"id":"9df1469f"},"outputs":[],"source":["cat_cols = ['preferred_foot', 'defensive_work_rate', 'attacking_work_rate']\n","\n","for col in cat_cols:\n","    indexer = StringIndexer(inputCol=col, outputCol=col+'_idx')\n","    data = indexer.fit(data).transform(data)\n","    \n","data = data.drop(*cat_cols)"]},{"cell_type":"markdown","id":"4e1ce37a","metadata":{"papermill":{"duration":0.040292,"end_time":"2022-08-12T11:33:12.816175","exception":false,"start_time":"2022-08-12T11:33:12.775883","status":"completed"},"tags":[],"id":"4e1ce37a"},"source":["### Combining Feature Columns\n"]},{"cell_type":"code","execution_count":null,"id":"30a3ed2f","metadata":{"execution":{"iopub.execute_input":"2022-08-12T11:33:12.900204Z","iopub.status.busy":"2022-08-12T11:33:12.899797Z","iopub.status.idle":"2022-08-12T11:33:13.002376Z","shell.execute_reply":"2022-08-12T11:33:13.001515Z"},"papermill":{"duration":0.147513,"end_time":"2022-08-12T11:33:13.005116","exception":false,"start_time":"2022-08-12T11:33:12.857603","status":"completed"},"tags":[],"id":"30a3ed2f"},"outputs":[],"source":["cols1 = data.columns\n","cols1.remove('overall_rating') #remove overall_rating -> we need this to be our label\n","\n","assembler = VectorAssembler(inputCols=cols1, outputCol='features')\n","\n","data1 = assembler.transform(data)"]},{"cell_type":"markdown","id":"de689e50","metadata":{"id":"de689e50"},"source":["### Set columns and Split\n","\n","Before modelling, the data are split into train and test data sets. We will make the train set bigger at this point as will incorporate cross validation later on."]},{"cell_type":"code","execution_count":null,"id":"75320723","metadata":{"execution":{"iopub.execute_input":"2022-08-12T11:33:13.062287Z","iopub.status.busy":"2022-08-12T11:33:13.061860Z","iopub.status.idle":"2022-08-12T11:33:13.111909Z","shell.execute_reply":"2022-08-12T11:33:13.110764Z"},"papermill":{"duration":0.081799,"end_time":"2022-08-12T11:33:13.114740","exception":false,"start_time":"2022-08-12T11:33:13.032941","status":"completed"},"tags":[],"id":"75320723"},"outputs":[],"source":["# We have created a new dataframe only consisting of the features column and the label column (actually price column but renamed)\n","df_data = data1.select(F.col('features'), F.col('overall_rating').alias('label'))\n","\n","df_train, df_test = df_data.randomSplit([0.75, 0.25])"]},{"cell_type":"markdown","id":"ca628a1f","metadata":{"id":"ca628a1f"},"source":["## Model Building\n","\n","\n","### Initialize Evaluator and Grid\n","As we are dealing with continuous values, we will be using Regressors to be trained on the data and then be used in prediction. Accordingly, we will have to use Regression Evaluator to evaluate all the Regressors we will be using."]},{"cell_type":"code","execution_count":null,"id":"2a50833b","metadata":{"execution":{"iopub.execute_input":"2022-08-12T11:33:13.172249Z","iopub.status.busy":"2022-08-12T11:33:13.171865Z","iopub.status.idle":"2022-08-12T11:33:13.209032Z","shell.execute_reply":"2022-08-12T11:33:13.208112Z"},"papermill":{"duration":0.068856,"end_time":"2022-08-12T11:33:13.211510","exception":false,"start_time":"2022-08-12T11:33:13.142654","status":"completed"},"tags":[],"id":"2a50833b"},"outputs":[],"source":["evaluator = RegressionEvaluator() # Can specify what metrics we want to use. Default metric is Root Mean Squared Error (RMSE)\n","grid = ParamGridBuilder().build()"]},{"cell_type":"code","execution_count":null,"id":"a3b0de82","metadata":{"execution":{"iopub.execute_input":"2022-08-12T11:33:13.268779Z","iopub.status.busy":"2022-08-12T11:33:13.268267Z","iopub.status.idle":"2022-08-12T11:39:01.550311Z","shell.execute_reply":"2022-08-12T11:39:01.549049Z"},"papermill":{"duration":348.313538,"end_time":"2022-08-12T11:39:01.552872","exception":false,"start_time":"2022-08-12T11:33:13.239334","status":"completed"},"tags":[],"id":"a3b0de82"},"outputs":[],"source":["#Random Forest Regressor\n","classifier_rf = RandomForestRegressor(featuresCol='features', labelCol='label')\n","cv_rf = CrossValidator(estimator=classifier_rf, evaluator=evaluator, estimatorParamMaps=grid, numFolds=10)\n","cv_model_rf = cv_rf.fit(df_train)"]},{"cell_type":"code","execution_count":null,"id":"6eb2b00b","metadata":{"id":"6eb2b00b"},"outputs":[],"source":["#Gradient Boosted Tree Regressor\n","classifier_gbt = GBTRegressor(featuresCol=\"features\", labelCol='label', maxIter=10)\n","cv_gbt = CrossValidator(estimator=classifier_gbt, evaluator=evaluator, estimatorParamMaps=grid, numFolds=10)\n","cv_model_gbt = cv_gbt.fit(df_train)"]},{"cell_type":"code","execution_count":null,"id":"f6d6c51b","metadata":{"id":"f6d6c51b"},"outputs":[],"source":["#Decision Tree Regressor\n","classifier_dt = DecisionTreeRegressor(featuresCol=\"features\", labelCol='label')\n","cv_dt = CrossValidator(estimator=classifier_dt, evaluator=evaluator, estimatorParamMaps=grid, numFolds=10)\n","cv_model_dt = cv_dt.fit(df_train)"]},{"cell_type":"code","execution_count":null,"id":"18b2fc0b","metadata":{"id":"18b2fc0b"},"outputs":[],"source":["#Linear Regression\n","classifier_lr = LinearRegression(maxIter=10, regParam=0.3, elasticNetParam=0.8)\n","cv_lr = CrossValidator(estimator=classifier_lr, evaluator=evaluator, estimatorParamMaps=grid, numFolds=10)\n","cv_model_lr = cv_lr.fit(df_train)"]},{"cell_type":"markdown","id":"631b7540","metadata":{"papermill":{"duration":0.033256,"end_time":"2022-08-12T11:39:01.620798","exception":false,"start_time":"2022-08-12T11:39:01.587542","status":"completed"},"tags":[],"id":"631b7540"},"source":["### Evaluation\n","\n","We will now get the average metrics of all models created by the regressors in the last step. And we will use the best model from each of the cross validated regressors to make predictions on the testing set. Lastly, this will all be presented in a dataframe for us to compare."]},{"cell_type":"code","execution_count":null,"id":"3fe3d7b5","metadata":{"id":"3fe3d7b5","outputId":"ebfb4e5b-c84d-47e6-d9e8-12826e1181c3"},"outputs":[{"name":"stdout","output_type":"stream","text":["[[2.7407853093463674], [2.512697899440387], [3.336886836746062], [2.9751355333918026]]\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Average Metrics (CV)</th>\n","      <th>Best Model R2 on Test Set</th>\n","      <th>Best Model RMSE on Test Set</th>\n","      <th>Best Model MAE on Test Set</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Random Forest Regressor</th>\n","      <td>2.740785</td>\n","      <td>0.848606</td>\n","      <td>2.731802</td>\n","      <td>1.942337</td>\n","    </tr>\n","    <tr>\n","      <th>Gradient Boosted Tree Regressor</th>\n","      <td>2.512698</td>\n","      <td>0.871742</td>\n","      <td>2.514421</td>\n","      <td>1.887638</td>\n","    </tr>\n","    <tr>\n","      <th>Decision Tree Regressor</th>\n","      <td>3.336887</td>\n","      <td>0.774089</td>\n","      <td>3.337055</td>\n","      <td>2.470341</td>\n","    </tr>\n","    <tr>\n","      <th>Linear Regression</th>\n","      <td>2.975136</td>\n","      <td>0.820623</td>\n","      <td>2.973568</td>\n","      <td>2.249735</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                 Average Metrics (CV)  \\\n","Random Forest Regressor                      2.740785   \n","Gradient Boosted Tree Regressor              2.512698   \n","Decision Tree Regressor                      3.336887   \n","Linear Regression                            2.975136   \n","\n","                                 Best Model R2 on Test Set  \\\n","Random Forest Regressor                           0.848606   \n","Gradient Boosted Tree Regressor                   0.871742   \n","Decision Tree Regressor                           0.774089   \n","Linear Regression                                 0.820623   \n","\n","                                 Best Model RMSE on Test Set  \\\n","Random Forest Regressor                             2.731802   \n","Gradient Boosted Tree Regressor                     2.514421   \n","Decision Tree Regressor                             3.337055   \n","Linear Regression                                   2.973568   \n","\n","                                 Best Model MAE on Test Set  \n","Random Forest Regressor                            1.942337  \n","Gradient Boosted Tree Regressor                    1.887638  \n","Decision Tree Regressor                            2.470341  \n","Linear Regression                                  2.249735  "]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["metrics = []\n","models = [cv_model_rf, cv_model_gbt, cv_model_dt, cv_model_lr]\n","\n","for model in models:\n","    metrics.append(model.avgMetrics)\n","print (metrics)\n","\n","for idx, model in enumerate(models): \n","    metrics[idx].append(RegressionEvaluator(predictionCol='prediction', labelCol='label', metricName='r2').evaluate(model.bestModel.transform(df_test)))\n","    metrics[idx].append(RegressionEvaluator(predictionCol='prediction', labelCol='label', metricName='rmse').evaluate(model.bestModel.transform(df_test)))\n","    metrics[idx].append(RegressionEvaluator(predictionCol='prediction', labelCol='label', metricName='mae').evaluate(model.bestModel.transform(df_test)))\n","\n","df = pd.DataFrame(metrics, index = ['Random Forest Regressor', 'Gradient Boosted Tree Regressor', 'Decision Tree Regressor', 'Linear Regression'], columns=['Average Metrics (CV)', 'Best Model R2 on Test Set', 'Best Model RMSE on Test Set', 'Best Model MAE on Test Set'])\n","\n","df"]}],"metadata":{"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":5}